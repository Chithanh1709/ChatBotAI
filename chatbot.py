import os
from typing import List
import logging

# Cáº¥u hÃ¬nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print("ğŸ”„ Äang khá»Ÿi táº¡o há»‡ thá»‘ng RAG vá»›i Google Gemini...")

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
    print("âœ… ÄÃ£ import google.generativeai")
except ImportError:
    print("âŒ KhÃ´ng thá»ƒ import Google Generative AI")
    GEMINI_AVAILABLE = False

try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    print("âš ï¸ Vui lÃ²ng cÃ i: pip install langchain-huggingface")
    from langchain_community.embeddings import HuggingFaceEmbeddings

try:
    from langchain_chroma import Chroma
except ImportError:
    print("âš ï¸ Vui lÃ²ng cÃ i: pip install langchain-chroma")
    from langchain_community.vectorstores import Chroma


# === Cáº¤U HÃŒNH ===
CHROMA_DB_PATH = "D:/chroma_food_rag"
COLLECTION_NAME = "food_products_vn"
GEMINI_MODEL_NAME = "models/gemini-pro-latest"  

def initialize_gemini_client():
    """Cáº¥u hÃ¬nh API key cho Gemini (khÃ´ng dÃ¹ng Client)"""
    if not GEMINI_AVAILABLE:
        return None

    try:
        genai.configure(api_key="AIzaSyBEM0RjTfvX1LW0IHZcqvZOo51s9TIlhSE")
        print(" ÄÃ£ cáº¥u hÃ¬nh Google Gemini")

        # Kiá»ƒm tra model cÃ³ kháº£ dá»¥ng khÃ´ng 
        try:
            model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            _ = model.generate_content("Xin chÃ o")
            print(f" Model {GEMINI_MODEL_NAME} kháº£ dá»¥ng")
        except Exception as e:
            print(f" Model {GEMINI_MODEL_NAME} cÃ³ thá»ƒ khÃ´ng kháº£ dá»¥ng: {e}")

        return True
    except Exception as e:
        print(f" Lá»—i cáº¥u hÃ¬nh Gemini: {e}")
        return None


def initialize_rag_system():
    """Khá»Ÿi táº¡o há»‡ thá»‘ng RAG"""
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="keepitreal/vietnamese-sbert",
            model_kwargs={"device": "cpu"}
        )
        print(" ÄÃ£ táº£i embedding model")

        vector_store = Chroma(
            persist_directory=CHROMA_DB_PATH,
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME
        )
        print(" ÄÃ£ káº¿t ná»‘i Chroma DB")

        test_results = vector_store.similarity_search("sá»¯a", k=1)
        print(f" Test thÃ nh cÃ´ng. TÃ¬m tháº¥y {len(test_results)} documents")

        return vector_store
    except Exception as e:
        print(f" Lá»—i khá»Ÿi táº¡o RAG: {e}")
        return None


def create_gemini_prompt(context: str, question: str) -> str:
    return f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n thá»±c pháº©m. HÃ£y sá»­ dá»¥ng thÃ´ng tin sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.

THÃ”NG TIN Sáº¢N PHáº¨M:
{context}

CÃ‚U Há»I: {question}

HÆ¯á»šNG DáºªN:
- CHá»ˆ sá»­ dá»¥ng thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p
- KHÃ”NG bá»‹a thÃ´ng tin
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin, nÃ³i "KhÃ´ng tÃ¬m tháº¥y"
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
- Táº­p trung vÃ o thÃ´ng tin thá»±c táº¿

Tráº£ lá»i:"""


def format_context_for_gemini(docs: List) -> str:
    if not docs:
        return "KhÃ´ng cÃ³ thÃ´ng tin sáº£n pháº©m."

    context = "DANH SÃCH Sáº¢N PHáº¨M:\n\n"
    for i, doc in enumerate(docs, 1):
        metadata = doc.metadata
        context += f"=== Sáº¢N PHáº¨M {i} ===\n"
        context += f"TÃªn: {metadata.get('name', 'ChÆ°a cÃ³ tÃªn')}\n"
        if metadata.get("price"):
            context += f"GiÃ¡: {metadata['price']:,} VNÄ\n"
        if metadata.get("category"):
            context += f"Danh má»¥c: {metadata['category']}\n"
        if metadata.get("ingredients"):
            context += f"ThÃ nh pháº§n: {metadata['ingredients']}\n"
        if metadata.get("benefits"):
            context += f"Lá»£i Ã­ch: {metadata['benefits']}\n"
        if metadata.get("storage"):
            context += f"Báº£o quáº£n: {metadata['storage']}\n"
        context += f"MÃ´ táº£: {doc.page_content}\n\n"
    return context


def ask_gemini(context: str, question: str) -> str:
    """Gá»i Gemini Ä‘Ãºng cÃ¡ch qua GenerativeModel"""
    try:
        prompt = create_gemini_prompt(context, question)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f" Lá»—i Gemini: {str(e)}"


def smart_fallback_response(docs: List, question: str) -> str:
    if not docs:
        return "KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p."

    response = f"ğŸ” TÃ¬m tháº¥y {len(docs)} sáº£n pháº©m liÃªn quan:\n\n"
    for i, doc in enumerate(docs, 1):
        metadata = doc.metadata
        response += f"{i}. **{metadata.get('name', 'Sáº£n pháº©m')}**\n"
        if metadata.get("price"):
            response += f"   ğŸ’µ GiÃ¡: {metadata['price']:,} VNÄ\n"
        if metadata.get("category"):
            response += f"   ğŸ“‚ Loáº¡i: {metadata['category']}\n"
        if metadata.get("benefits"):
            short = metadata["benefits"][:60] + "..." if len(metadata["benefits"]) > 60 else metadata["benefits"]
            response += f"   ğŸ’« {short}\n"
        response += "\n"

    response += "ğŸ’¡ *Äá»ƒ cÃ³ cÃ¢u tráº£ lá»i chi tiáº¿t, hÃ£y cáº¥u hÃ¬nh Google Gemini API*"
    return response


def is_food_related(query: str) -> bool:
    query = query.lower()
    food_keywords = [
        "thá»±c pháº©m", "sáº£n pháº©m", "Äƒn", "uá»‘ng", "mua", "náº¥u", "mÃ³n",
        "thá»‹t", "cÃ¡", "rau", "sá»¯a", "bÃ¡nh", "mÃ¬", "gáº¡o", "Ä‘áº­u",
        "thÃ nh pháº§n", "báº£o quáº£n", "dá»‹ á»©ng", "giÃ¡", "cÃ´ng dá»¥ng"
    ]
    return any(kw in query for kw in food_keywords)


def main():
    gemini_ready = initialize_gemini_client()
    vector_store = initialize_rag_system()
    if not vector_store:
        return

    print("\n" + "=" * 60)
    print("ğŸ’¬ Há»† THá»NG TÆ¯ Váº¤N THá»°C PHáº¨M")
    print("=" * 60)

    if gemini_ready:
        print(" Äang sá»­ dá»¥ng Google Gemini")
    else:
        print("Cháº¿ Ä‘á»™ cÆ¡ báº£n (cáº§n cÃ i google-generativeai)")
        print("Cháº¡y: pip install -U google-generativeai")

    print("\nNháº­p 'thoÃ¡t' Ä‘á»ƒ káº¿t thÃºc")
    print("=" * 60)

    while True:
        user_input = input("\n Báº¡n há»i: ").strip()
        if user_input.lower() in ["thoÃ¡t", "exit", "quit", "q"]:
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break
        if not user_input:
            continue
        if not is_food_related(user_input):
            print(" TÃ´i chá»‰ há»— trá»£ cÃ¢u há»i vá» thá»±c pháº©m.")
            continue

        print("ğŸ¤– Äang tÃ¬m kiáº¿m...")
        docs = vector_store.similarity_search(user_input, k=3)

        if not docs:
            print(" KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p.")
            continue

        if gemini_ready:
            context = format_context_for_gemini(docs)
            response = ask_gemini(context, user_input)
            print(f"\n Tráº£ lá»i:\n{response}")
        else:
            response = smart_fallback_response(docs, user_input)
            print(f"\n{response}")

class ChatBot:
    def __init__(self):
        logger.info("ğŸ”„ Initializing ChatBot...")
        self.gemini_ready = initialize_gemini_client()
        self.vector_store = initialize_rag_system()
        logger.info("âœ… ChatBot initialized")

    def get_answer(self, question: str) -> str:
        try:
            # VALIDATE Ká»¸ HÆ N
            if question is None:
                return "âŒ CÃ¢u há»i khÃ´ng há»£p lá»‡ (None)."
                
            question_str = str(question).strip() if question else ""
            
            if not question_str:
                return "âŒ Vui lÃ²ng nháº­p cÃ¢u há»i."
                
            if question_str.lower() in ["none", "null", "undefined"]:
                return "âŒ CÃ¢u há»i khÃ´ng há»£p lá»‡."
                
            logger.info(f"ğŸ¤– Processing question: '{question_str}'")
            
            # Kiá»ƒm tra há»‡ thá»‘ng RAG
            if not self.vector_store:
                return "âš ï¸ Há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c báº£o trÃ¬. Vui lÃ²ng thá»­ láº¡i sau."

            # Kiá»ƒm tra liÃªn quan Ä‘áº¿n thá»±c pháº©m
            if not is_food_related(question_str):
                return "â— TÃ´i chá»‰ há»— trá»£ cÃ¢u há»i vá» thá»±c pháº©m vÃ  sáº£n pháº©m."

            # TÃ¬m kiáº¿m trong database
            logger.info("ğŸ” Searching in vector database...")
            docs = self.vector_store.similarity_search(question_str, k=3)
            logger.info(f"ğŸ“š Found {len(docs)} relevant documents")

            if not docs:
                return "âŒ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p vá»›i cÃ¢u há»i cá»§a báº¡n."

            # Táº¡o response
            if self.gemini_ready:
                logger.info("ğŸ¤– Using Gemini for response...")
                context = format_context_for_gemini(docs)
                response = ask_gemini(context, question_str)
                logger.info("âœ… Gemini response generated")
                return response
            else:
                logger.info("ğŸ“ Using fallback response...")
                return smart_fallback_response(docs, question_str)
                
        except Exception as e:
            logger.error(f"ğŸ’¥ Error in get_answer: {e}", exc_info=True)
            return f"âŒ ÄÃ£ xáº£y ra lá»—i há»‡ thá»‘ng: {str(e)}"