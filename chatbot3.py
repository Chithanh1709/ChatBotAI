import os, requests, json, logging
from typing import List
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("RAG")

MEGA_URL = "https://ai.megallm.io/v1/chat/completions"
MEGA_KEY = "sk-mega-9e02941cc7286047dfe1dc53d2d94a1afddddd677e4769b5189ed82a992f2f43"       
MEGA_MODEL = "llama3.3-70b-instruct"

DB_PATH = "D:/chroma_food_rag"
COL = "food_products_vn"
PRODUCT_URL = "http://localhost:4200/product"

emb = HuggingFaceEmbeddings(model_name="keepitreal/vietnamese-sbert", model_kwargs={"device":"cpu"})
vecdb = Chroma(persist_directory=DB_PATH, embedding_function=emb, collection_name=COL)

def mega(messages, max_tokens=600, temperature=0.1):
    r = requests.post(
        MEGA_URL,
        headers={"Authorization":f"Bearer {MEGA_KEY}","Content-Type":"application/json"},
        json={"model":MEGA_MODEL,"messages":messages,"max_tokens":max_tokens,"temperature":temperature},
        timeout=60
    )
    if r.status_code!=200: return f"L·ªói MegaLLM: {r.text}"
    return r.json()["choices"][0]["message"]["content"]

def classify(query):
    msg=[
        {"role":"system","content":"Tr·∫£ l·ªùi duy nh·∫•t 'FOOD' ho·∫∑c 'OTHER'. N·∫øu c√¢u h·ªèi li√™n quan th·ª±c ph·∫©m, s·∫£n ph·∫©m ƒÉn u·ªëng, th√†nh ph·∫ßn, dinh d∆∞·ª°ng ‚Üí FOOD."},
        {"role":"user","content":query}
    ]
    r = mega(msg, max_tokens=2).strip().upper()
    return r=="FOOD"

def ctx_format(docs):
    if not docs: return "Kh√¥ng c√≥ s·∫£n ph·∫©m."
    out="DANH S√ÅCH S·∫¢N PH·∫®M:\n\n"
    for i,d in enumerate(docs,1):
        m=d.metadata
        pid=m.get("product_id") or m.get("id") or "unknown"
        out+=f"=== SP {i} ‚Äì ID {pid} ===\n"
        out+=f"T√™n: {m.get('name','(kh√¥ng t√™n)')}\n"
        out+=f"Gi√°: {m.get('price','?')}\n"
        out+=f"Lo·∫°i: {m.get('category','?')}\n"
        out+=f"{d.page_content}\n\n"
    return out

def rag_answer(query):
    docs = vecdb.similarity_search(query, k=4)
    if not docs: return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."
    ctx = ctx_format(docs)
    prompt=[
        {"role":"system","content":"B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th·ª±c ph·∫©m. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n context."},
        {"role":"user","content":f"TH√îNG TIN:\n{ctx}\nC√ÇU H·ªéI: {query}\nTr·∫£ l·ªùi:"}
    ]
    ans = mega(prompt)
    ans+="\n\nüîó S·∫¢N PH·∫®M LI√äN QUAN:\n"
    for d in docs:
        m=d.metadata
        pid=m.get("product_id") or m.get("id") or None
        name=m.get("name","S·∫£n ph·∫©m")
        if pid:
            ans+=f"- {name}: {PRODUCT_URL}/{pid}\n"
        else:
            ans+=f"- {name}: (kh√¥ng c√≥ ID)\n"
    return ans

def chat(query):
    if not query.strip(): return "‚ùó H√£y nh·∫≠p c√¢u h·ªèi."
    if not classify(query): return "‚ö†Ô∏è T√¥i ch·ªâ t∆∞ v·∫•n li√™n quan ƒë·∫øn th·ª±c ph·∫©m."
    return rag_answer(query)

if __name__=="__main__":
    print("=== RAG + MegaLLM ü•ó ===")
    while True:
        q=input("‚ùì ")
        if q.lower() in ["exit","quit","tho√°t"]: break
        print("üëâ", chat(q))